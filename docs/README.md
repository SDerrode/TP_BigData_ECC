
# TP _Big Data_, ECC

Cet espace recueille les fichiers nécessaires à la réalisation des travaux pratiques du module de _Technologies Informatique du Big Data_, enseignés à l'École Centrale de Casablanca.

Les cours sont disponibles sur [edunao](https://centrale-casablanca.edunao.com/course/view.php?id=179).

Merci de consulter régulièrement ce site, pour le bon déroulement du cours et pour prendre en compte les éventuels changements.

[_Stéphane Derrode_](mailto:stephane.derrode@ec-lyon.fr), École Centrale de Lyon, Dpt MI, LIRIS (CNRS UMR 5205).

----
## Informations générales

**Volume de cours et travail personnel** : 

> - 12 séances de 2h; La première moitié des enseignements se fera en distanciel (séances #1 à #6), et la seconde moitié en présentiel, lors de ma venue à l'ECC en janvier 2022.     
> - des _homeworks_ à faire entre 2 séances (pour 2h/4h de travail personnel ou en binôme).
> - Une fiche de synthèse à rédiger sur un sujet associé au big data (cf consignes ci-dessous).

**Évaluation** :

> - Rédaction d'une fiche de synthèse (FS). _Cf_ explications données à la fin du premier cours, et le patron _Markdown_ pour rédiger la FS dans le répertoire [Template_FS](./Template_FS/README.md);
> - Rédaction de CR (Compte-Rendus) de TP à rendre régulièrement (le travail à faire est spécifié dans les séances concernées).    

----
## Déroulé des séances

### Séance #1 - Introduction au _Big Data_

  - **Objectif du cours**
  > - Présentation des objectifs du module
  > - Introduction au _Big Data_: enjeux éthiques, économiques & scientifiques.   
  
  - **Travail hebdomadaire à faire pour la séance suivante**
  > - Regardez les vidéos non vues en cours, dont les liens figurent dans les slides, et certaines des vidéos suivantes (cela pourra vous donner des idées sur le sujet de votre FS) :   
       > 
     >   - [Le Big Data pour mieux nous comprendre](https://www.ted.com/talkkenneth_cukier_big_data_is_better_data?language=fr).    
     >   - [_Let's pool our medical data_](https://www.ted.com/talks/john_wilbanks_let_s_pool_our_medical_data).    
     >   - [_Why privacy matters?_](https://www.ted.com/talks/glenn_greenwald_why_privacy_matters#t-46573).    
     >   - [_Big Data will impact every part of your life_](https://www.youtube.com/watch?v=0Q3sRSUYmys).    
     >   - [_Big data and dangerous ideas_](https://www.youtube.com/watch?v=tLQoncvCKxs).    
     >   - [_Big Data and the Rise of Augmented Intelligence_](https://www.youtube.com/watch?v=mKZCa_ejbfg).     
     >   - [_How Big Data Can Influence Decisions That Actually Matter_](https://www.youtube.com/watch?v=C6WKt6fJiso).     
     >   - [_Is Big Data Killing Creativity?_](https://www.youtube.com/watch?v=A1XibEzp6K0).     
     >   - [_Analyzing and modeling complex and big data_](https://www.youtube.com/watch?v=8DqQCZMawNg).      
     >   - [_How to Monetize Big Data_](https://www.youtube.com/watch?v=8DqQCZMawNg).     
     >   - [_How to predict the future with big data_](https://www.youtube.com/watch?v=J0bp2kUh9hw).    
   
---
### Séance #2 - Git & _Open Data_

  - **Objectif du cours**
  > - Sondage [wooclap - https://www.wooclap.com/FETQLU](https://www.wooclap.com/FETQLU)
  > - Présentation de la FS par groupe de 4 à 5 étudiants. Celle-ci doit être préparée tout au long du module, la date de remise est fixée à la date de la dernière séance de cours. Les consignes pour la rédaction (utilisation de _Markdown_ et de _git_) et le rendu sont détaillées dans le répertoire [Template_FS](./Template_FS/README.md).
  > - Introduction à l'_Open Data_. Vidéos:
       > 
     >   - [L'open data à la loupe](https://www.youtube.com/watch?v=6WtviEVPkJI).    
     >   - [_How we found the worst place to park in New York City_](https://www.ted.com/talks/ben_wellington_how_we_found_the_worst_place_to_park_in_new_york_city_using_big_data).
       >
  > - Apprentissage de _git_, avec l'outil _GitHub Desktop_ et directement en ligne de commandes (avec un _Terminal_). Les scénarios des tutoriels sont disponibles dans le dossier [git](./tuto-git-gitlab).
  

  - **Complément sur la séance #2**
  >   - [_Demand on a more open-source government_](https://www.ted.com/talks/beth_noveck_demand_a_more_open_source_government#t-66622).    
  >   - [L'Open Data, Avenir des Big Data](https://www.youtube.com/watch?v=MUI6Rwn4Qq0).
  >   - [_Linked Open Data - What is it?_](https://www.youtube.com/watch?v=uju4wT9uBIA).

---
### Séance #3 - _Linked Data_

  - **Objectif du cours**
  > - Sondage [wooclap](https://www.wooclap.com/MIZTRT)
  > - Introduction aux données liées (_Linked Data_ ou _Linked Open Data_).    
  > - Liens vers des vidéos vues en cours :
       > 
     >   - [Tim Berners-Lee : _The next Web_](https://www.ted.com/talks/tim_berners_lee_the_next_web).
     >   - [_What is Linked Data? Manu Sporny_](https://www.youtube.com/watch?v=4x_xzT5eF5Q).

  - **Travail hebdomadaire à faire pour la séance suivante**
  > - Formez les groupes, déposez les noms et les adresses mail et les sujets de votre FS sur le fichier [hébergé ici](https://partage.liris.cnrs.fr/index.php/s/FegdnkcY7xSgAr2).    
  > - Après avoir créé un compte sur la plateforme [GitLab](https://gitlab.com/users/sign_in), créez un projet privé pour la FS (me désigner `reporter` de chaque FS, mon pseudo : `Derrode`), selon les modalités exposées dans le dossier [Template_FS](./Template_FS/README.md). Cela me permettra de voir vos travaux (espionnage de votre travail !).    
    

---
### Séance #4 - TP _Linked Data_ et _SparQL_ (1/2)
 
  - **Objectif de la séance**
  > - Fin de l'introduction aux données liées et présentation du [TP1](./TP1) sur _SparQL_.    
  > - Travail sur le [TP1](./TP1) sur _SparQL_.

  - **Travaux pratiques**
  > - Préparer les requêtes 2 à 6 du [TP1](./TP1), la solution de la requête 1 est déjà donnée dans l'énoncé. N'hésitez pas à sauvegarder vos requêtes dans un fichier texte (au format _Markdown_ ?) pour pouvoir les rejouer plus tard.
  
  - **Travail hebdomadaire à faire pour la séance suivante**
  > - Terminez si nécessaire les requêtes du [TP1](./TP1).

---
### Séance #5 - TP _Linked Data_ et _SparQL_ (2/2)
 
  - **Objectif de la séance**
  > - Présentation des derniers slides du cours LOD, sur les points d'accès.
  > - Travaillez sur le rendu de TP (_cf_ ci-dessous).

  - **Travail à rendre pour la prochaine séance (individuel)**
  > - Choisissez une base de données `linked data` (autre que _DBPedia_) et inventez **deux requêtes** sur cette base. Vous pouvez utiliser une des bases vues en cours, ou en chercher une nouvelle à partir de ces sites :
       > 
     >   - [The Linked Open Data Cloud](https://lod-cloud.net/datasets). En recherchant le mot `plane`vous obtiendrez un accès la la bas de la Nasa sur les missions spatiales et les astraonautes: [NASA Space Flight & Astronaut data in RDF](https://lod-cloud.net/dataset/data-incubator-nasa).  
     >   - [Linked open vocabularies](https://lov.linkeddata.es/dataset/lov/).  
     >   - [DataHub](https://old.datahub.io). 
  >  
  > - Rédigez un petit rapport (rapport individuel de 2 pages maxi, au format _Markdown_) comprenant, pour chacune des 2 requêtes :  
       > 
     >   - Préciser le *Sparql endpoint* permettant d'accéder à la base que vous interrogez. Par exemple, pour la base des prix nobels, le *endpoint* est : `http://data.nobelprize.org/sparql`, pour DBpedia : `http://dbpedia.org/sparql`.
     >   - Le dessin _RDF_ de la requête (vous pouvez utiliser [draw.io](https://app.diagrams.net) pour dessiner les graphiques),     
     >   - Le code _SparQL_ de la requête (que je puisse la rejouer dans _Yasgui_),    
     >   - Les 3 ou 4 premiers résultats de la requête (copie d'écran).   
     > - N'oubliez pas d'inscrire votre nom sur le rapport, et de déposer un seul fichier compressé nommé _VotreNom_rendu1.zip_, sur [edunao](https://centrale-casablanca.edunao.com/course/view.php?id=179) **au plus tard le vendredi 17 décembre, 23h55**. Le site de dépôt de la plateforme est programmé pour ne plus accepter de compte-rendu au-delà. 
     > - Ce rapport sera évalué et comptera dans votre note finale. La note prendra en compte l'originalité de la requête, et la qualité de son écriture bien sûr !
  > - Voici un exemple de rendu qui répond aux consignes : [Exemple_Rendu_TP1](./TP1/Exemple_Rendu_TP1.zip).

---
### Séance #6 - cours _Hadoop_ (1/2)

  - **Objectif du cours**
  > - Retour sur les CRs du [TP #1](./TP1)
  > - Présentation du framework _Hadoop_/_map-reduce_
  > - Présentation du [TP #2](./TP2) qui se déroulera en séance #7 (CR à rendre seul ou en binôme).

  - **Travail hebdomadaire à faire pour la séance suivante**
  > - En préparation à ce [TP #2](./TP2), installez _Docker_ et le container _Docker Linux/Hadoop_ selon les consignes données dans **la PARTIE 2** du TP #2. Attention, le téléchargement est très volumineux et nécessite une machine avec au moins 3 GO libre de disque dur! Prenez-vous en avance pour faire cette installation!

---
### Séances #7 et #8 - Fin du cours _Hadoop_ (2/2) et début du TP Hadoop

  - **Objectif du cours**
  > - Fin de la présentation du cours sur le framework _Hadoop_/_map-reduce_
  > - Bilan des installations de _Docker_ et du container.
  > - Avancez sur la seconde partie du [TP #2](./TP2) concernant précisément `Hadoop map-reduce`.

  - **Travail hebdomadaire à faire pour la séance suivante**
  > - Avancez sur le [TP #2](./TP2). La séance #8 sera la dernière consacrée à ce _framework_.

---
### Séances #9 et #10 - Fin du TP _Hadoop_ et cours _Spark_

  - **Objectif de la séance**
  > - Fin du [TP #2](./TP2) sur Hadoop
  > - Présentation du framework _Spark_.

  - **Travail à rendre pour la prochaine séance (seul ou en binôme)**
  > - Déposez l'algorithme _map-reduce_ correspondant à l'exercice intitulé `Énoncé du CR de TP2`  (uniquement cet exercice) sur la plateforme [edunao](https://centrale-casablanca.edunao.com/course/view.php?id=179) **à la date indiquée sur Eduano**. Le site de la plateforme est programmé pour ne plus accepter de dépôt au-delà. 
  > - Sur le CR, rédigé en *markdown*, merci d'inclure les scripts permettant de répondre à la question posée, et d'ajouter un extrait des résultats obtenus sur le fichier proposé. Tout ajout, *p. ex.* une variante de l'algorithme, ou un test sur d'autres fichiers de vocabulaires..., sera TRES apprécié. Inscrivez sur le CR toutes les informations me permettant de rejouer ces ajouts.  
  > - N'oubliez pas d'inscrire votre nom / vos noms sur les scripts, et de déposer un seul fichier compressé nommé _VosNoms_rendu2.zip_.
  > - Cet algorithme sera évalué et comptera dans votre note finale. La note prendra en compte la qualité et la clarté du code (qui doit être légèrement commenté, avec des noms de variables qui donnent du sens à votre programme) !

---
### Séance #11 et #12 - TP _Spark_

  - **Travaux pratiques**
  > - Commencez le [TP #3](./TP3), depuis la section `Tester les scripts vus en cours`. 
  > - La partie 4 de ce TP (portant sur _Spark streaming_) est optionnelle.

  - **Travail hebdomadaire à faire pour la séance suivante**
  > - Cette année, aucun CR pour ce TP n'est demandé.
<!--
  > - Déposez le CR (écrit en _Markdown_) qui portera sur l'algorithme _pyspark_ de l'exercice 2 de la partie 3 du TP (uniquement cet exercice portant sur une base de films) sur la plateforme [edunao](https://centrale-casablanca.edunao.com/course/view.php?id=179) **à la date indiquée sur edunao**. Le site de la plateforme est programmé pour ne plus accepter de dépôt au-delà. 
  > - N'oubliez pas d'inscrire votre nom sur le rapport, et de déposer un seul fichier compressé nommé _VotreNom_rendu3.zip_.
  > - Ce rapport sera évalué et comptera dans votre note finale. La note prendra en compte la qualité et la clarté du code (qui doit être légèrement commenté, avec des noms de variables qui donnent du sens à votre programme), ainsi que l'originalité et la complexité de la requête que vous aurez choisie !
-->